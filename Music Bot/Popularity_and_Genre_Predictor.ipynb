{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64263016",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import statements\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import plotly as px\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import string\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a86c62d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv files\n",
    "df_one = pd.read_csv(\"train.csv\")\n",
    "df_two = pd.read_csv('test.csv')\n",
    "\n",
    "# concatenates the files into one dataframe\n",
    "df_music = pd.concat([df_one, df_two], ignore_index=True)\n",
    "df_music.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# normalizing dataframe headers and replaceing double spaces in vendor name\n",
    "df_music.columns = df_music.columns.str.lower().str.replace(r'\\s+', '_', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5c709c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defines a function to exract featured artists if there are any\n",
    "def extract_featured_artist(track_name):\n",
    "    pattern = r\"\\(feat\\. ([^)]+)\\)\"  # notates a pattern to match \"(feat. artist)\"\n",
    "    match = re.search(pattern, track_name)\n",
    "   # if statement when we find a match\n",
    "    if match:\n",
    "        featured_artist = match.group(1)\n",
    "        track_name = re.sub(pattern, \"\", track_name)  # removes the \"(feat. artist)\" from track_name\n",
    "        return track_name.strip(), featured_artist.strip()\n",
    "    \n",
    "    return track_name.strip(), None\n",
    "\n",
    "# cleans track name of any excess hyphenations\n",
    "def track_name_cleaner(track_name):\n",
    "    \n",
    "    if track_name is not None:\n",
    "        # Remove all text after the hyphen '-'\n",
    "        track_name = track_name.split('-')[0].strip()\n",
    "    \n",
    "    return track_name\n",
    "# makes sure characters are printable values\n",
    "def is_printable(text):\n",
    "    return all(32 <= ord(char) <= 127 for char in text)\n",
    "\n",
    "# turns milliseconds into minutes\n",
    "def convert_ms_to_min(time):\n",
    "    if time > 60:\n",
    "        return time / (1000 * 60)  # convert milliseconds to minutes\n",
    "    else:\n",
    "        return time  # return the original value if it's already in minutes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2d1d82f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist_name</th>\n",
       "      <th>track_name</th>\n",
       "      <th>popularity</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>duration_in_min/ms</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>class</th>\n",
       "      <th>featured_artist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bruno Mars</td>\n",
       "      <td>That's What I Like</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.854</td>\n",
       "      <td>0.564</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-4.964</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.017100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0849</td>\n",
       "      <td>0.8990</td>\n",
       "      <td>134.071</td>\n",
       "      <td>234596.0</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Gucci Mane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Boston</td>\n",
       "      <td>Hitch a Ride</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.382</td>\n",
       "      <td>0.814</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-7.230</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0406</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.004010</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.5690</td>\n",
       "      <td>116.454</td>\n",
       "      <td>251733.0</td>\n",
       "      <td>4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Raincoats</td>\n",
       "      <td>No Side to Fall In</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.434</td>\n",
       "      <td>0.614</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-8.334</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0525</td>\n",
       "      <td>0.486000</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>0.3940</td>\n",
       "      <td>0.7870</td>\n",
       "      <td>147.681</td>\n",
       "      <td>109667.0</td>\n",
       "      <td>4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Deno</td>\n",
       "      <td>Lingo</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.597</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-6.528</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0555</td>\n",
       "      <td>0.021200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1220</td>\n",
       "      <td>0.5690</td>\n",
       "      <td>107.033</td>\n",
       "      <td>173968.0</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>J.I &amp; Chunkz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Red Hot Chili Peppers</td>\n",
       "      <td>Nobody Weird Like Me - Remastered</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.975</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-4.279</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2160</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>0.016100</td>\n",
       "      <td>0.1720</td>\n",
       "      <td>0.0918</td>\n",
       "      <td>199.060</td>\n",
       "      <td>229960.0</td>\n",
       "      <td>4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             artist_name                         track_name  popularity  \\\n",
       "0             Bruno Mars                 That's What I Like        60.0   \n",
       "1                 Boston                       Hitch a Ride        54.0   \n",
       "2          The Raincoats                 No Side to Fall In        35.0   \n",
       "3                   Deno                              Lingo        66.0   \n",
       "4  Red Hot Chili Peppers  Nobody Weird Like Me - Remastered        53.0   \n",
       "\n",
       "   danceability  energy   key  loudness  mode  speechiness  acousticness  \\\n",
       "0         0.854   0.564   1.0    -4.964     1       0.0485      0.017100   \n",
       "1         0.382   0.814   3.0    -7.230     1       0.0406      0.001100   \n",
       "2         0.434   0.614   6.0    -8.334     1       0.0525      0.486000   \n",
       "3         0.853   0.597  10.0    -6.528     0       0.0555      0.021200   \n",
       "4         0.167   0.975   2.0    -4.279     1       0.2160      0.000169   \n",
       "\n",
       "   instrumentalness  liveness  valence    tempo  duration_in_min/ms  \\\n",
       "0               NaN    0.0849   0.8990  134.071            234596.0   \n",
       "1          0.004010    0.1010   0.5690  116.454            251733.0   \n",
       "2          0.000196    0.3940   0.7870  147.681            109667.0   \n",
       "3               NaN    0.1220   0.5690  107.033            173968.0   \n",
       "4          0.016100    0.1720   0.0918  199.060            229960.0   \n",
       "\n",
       "   time_signature  class featured_artist  \n",
       "0               4    5.0      Gucci Mane  \n",
       "1               4   10.0            None  \n",
       "2               4    6.0            None  \n",
       "3               4    5.0    J.I & Chunkz  \n",
       "4               4   10.0            None  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_music[\"featured_artist\"] = \"\" # makes a new column in the datafram for featured artists\n",
    "\n",
    "# sets up a for loop to run our function\n",
    "for index, row in df_music.iterrows():\n",
    "    track_name = row[\"track_name\"]\n",
    "    track_name, featured_artist = extract_featured_artist(track_name)\n",
    "    df_music.at[index, \"track_name\"] = track_name\n",
    "    df_music.at[index, \"featured_artist\"] = featured_artist.strip() if featured_artist else None \n",
    "# show df\n",
    "df_music.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3957a85a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_name</th>\n",
       "      <th>popularity</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>duration_in_min/ms</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>class</th>\n",
       "      <th>featured_artist</th>\n",
       "      <th>artist_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>That's What I Like</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.854</td>\n",
       "      <td>0.564</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-4.964</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.017100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0849</td>\n",
       "      <td>0.8990</td>\n",
       "      <td>134.071</td>\n",
       "      <td>3.909933</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Gucci Mane</td>\n",
       "      <td>Bruno Mars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hitch a Ride</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.382</td>\n",
       "      <td>0.814</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-7.230</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0406</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.004010</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.5690</td>\n",
       "      <td>116.454</td>\n",
       "      <td>4.195550</td>\n",
       "      <td>4</td>\n",
       "      <td>10.0</td>\n",
       "      <td></td>\n",
       "      <td>Boston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No Side to Fall In</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.434</td>\n",
       "      <td>0.614</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-8.334</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0525</td>\n",
       "      <td>0.486000</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>0.3940</td>\n",
       "      <td>0.7870</td>\n",
       "      <td>147.681</td>\n",
       "      <td>1.827783</td>\n",
       "      <td>4</td>\n",
       "      <td>6.0</td>\n",
       "      <td></td>\n",
       "      <td>The Raincoats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lingo</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.597</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-6.528</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0555</td>\n",
       "      <td>0.021200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1220</td>\n",
       "      <td>0.5690</td>\n",
       "      <td>107.033</td>\n",
       "      <td>2.899467</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>J.I &amp; Chunkz</td>\n",
       "      <td>Deno</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nobody Weird Like Me</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.975</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-4.279</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2160</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>0.016100</td>\n",
       "      <td>0.1720</td>\n",
       "      <td>0.0918</td>\n",
       "      <td>199.060</td>\n",
       "      <td>3.832667</td>\n",
       "      <td>4</td>\n",
       "      <td>10.0</td>\n",
       "      <td></td>\n",
       "      <td>Red Hot Chili Peppers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             track_name  popularity  danceability  energy   key  loudness  \\\n",
       "0    That's What I Like        60.0         0.854   0.564   1.0    -4.964   \n",
       "1          Hitch a Ride        54.0         0.382   0.814   3.0    -7.230   \n",
       "2    No Side to Fall In        35.0         0.434   0.614   6.0    -8.334   \n",
       "3                 Lingo        66.0         0.853   0.597  10.0    -6.528   \n",
       "4  Nobody Weird Like Me        53.0         0.167   0.975   2.0    -4.279   \n",
       "\n",
       "   mode  speechiness  acousticness  instrumentalness  liveness  valence  \\\n",
       "0     1       0.0485      0.017100          0.000000    0.0849   0.8990   \n",
       "1     1       0.0406      0.001100          0.004010    0.1010   0.5690   \n",
       "2     1       0.0525      0.486000          0.000196    0.3940   0.7870   \n",
       "3     0       0.0555      0.021200          0.000000    0.1220   0.5690   \n",
       "4     1       0.2160      0.000169          0.016100    0.1720   0.0918   \n",
       "\n",
       "     tempo  duration_in_min/ms  time_signature  class featured_artist  \\\n",
       "0  134.071            3.909933               4    5.0      Gucci Mane   \n",
       "1  116.454            4.195550               4   10.0                   \n",
       "2  147.681            1.827783               4    6.0                   \n",
       "3  107.033            2.899467               4    5.0    J.I & Chunkz   \n",
       "4  199.060            3.832667               4   10.0                   \n",
       "\n",
       "             artist_name  \n",
       "0             Bruno Mars  \n",
       "1                 Boston  \n",
       "2          The Raincoats  \n",
       "3                   Deno  \n",
       "4  Red Hot Chili Peppers  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataframe changes\n",
    "# Convert the original featured_artist into a list\n",
    "df_music['featured_artist'] = df_music['featured_artist'].apply(lambda x: x.split(',') if isinstance(x, str) else x)\n",
    "\n",
    "# Split the artist_name into main_artist and new_featured_artists\n",
    "df_music['main_artist'] = df_music['artist_name'].apply(lambda x: x.split(',', 1)[0].split('&', 1)[0].strip())\n",
    "df_music['new_featured_artists'] = df_music['artist_name'].apply(lambda x: [i.strip() for sublist in x.split(',', 1)[1:] + x.split('&', 1)[1:] for i in sublist.split('&') if sublist])\n",
    "\n",
    "# Merge the original featured_artist list and new_featured_artists list\n",
    "df_music['featured_artist'] = df_music['featured_artist'].apply(lambda x: x if isinstance(x, list) else []) + df_music['new_featured_artists']\n",
    "\n",
    "# Convert the merged list back into a string, if necessary\n",
    "df_music['featured_artist'] = df_music['featured_artist'].apply(lambda x: ', '.join(x) if isinstance(x, list) else x)\n",
    "\n",
    "# Remove artist_name and new_featured_artists columns and rename main_artist as artist_name\n",
    "df_music = df_music.drop(['artist_name', 'new_featured_artists'], axis=1)\n",
    "df_music = df_music.rename(columns={'main_artist': 'artist_name'})\n",
    "\n",
    "# apply the track_name_cleaner function to all rows\n",
    "df_music[\"track_name\"] = df_music[\"track_name\"].apply(track_name_cleaner)\n",
    "\n",
    "# Assuming your string column is named \"your_string_column\"\n",
    "df_music[\"track_name\"] = df_music[\"track_name\"].apply(lambda x: x if is_printable(x) else 'UNKNOWN')\n",
    "\n",
    "# replace NaN values in \"instrumentalness\" column with 0's\n",
    "df_music.fillna(0, inplace=True)\n",
    "\n",
    "# Apply the function to your column\n",
    "df_music['duration_in_min/ms'] = df_music['duration_in_min/ms'].apply(convert_ms_to_min)\n",
    "\n",
    "# show df\n",
    "df_music.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ad07fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify categorical columns in the dataset\n",
    "categorical_cols = ['featured_artist', 'artist_name']\n",
    "\n",
    "# Apply One-Hot Encoding to each categorical column\n",
    "df_music = pd.get_dummies(df_music, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "df_music.set_index('track_name', inplace=True)\n",
    "\n",
    "# Assuming 'song_popularity' is the target column, and other columns are features\n",
    "X = df_music.drop('popularity', axis=1)\n",
    "y = df_music['popularity']\n",
    "\n",
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af62603c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haxz\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m lr_model \u001b[38;5;241m=\u001b[39m LogisticRegression(max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20000\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m45\u001b[39m)\n\u001b[0;32m      5\u001b[0m grid_search_lr \u001b[38;5;241m=\u001b[39m GridSearchCV(lr_model, param_grid_lr, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m grid_search_lr\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m      8\u001b[0m best_lr_model \u001b[38;5;241m=\u001b[39m grid_search_lr\u001b[38;5;241m.\u001b[39mbest_estimator_\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    868\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    870\u001b[0m     )\n\u001b[0;32m    872\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 874\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    878\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1386\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1387\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1388\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grid))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    814\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    815\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    816\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    818\u001b[0m         )\n\u001b[0;32m    819\u001b[0m     )\n\u001b[1;32m--> 821\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    822\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    823\u001b[0m         clone(base_estimator),\n\u001b[0;32m    824\u001b[0m         X,\n\u001b[0;32m    825\u001b[0m         y,\n\u001b[0;32m    826\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[0;32m    827\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[0;32m    828\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[0;32m    829\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[0;32m    830\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[0;32m    831\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[0;32m    832\u001b[0m     )\n\u001b[0;32m    833\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[0;32m    834\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params), \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, groups))\n\u001b[0;32m    835\u001b[0m     )\n\u001b[0;32m    836\u001b[0m )\n\u001b[0;32m    838\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    839\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    841\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    842\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    843\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1085\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1076\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1077\u001b[0m     \u001b[38;5;66;03m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[0;32m   1078\u001b[0m     \u001b[38;5;66;03m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1082\u001b[0m     \u001b[38;5;66;03m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[0;32m   1083\u001b[0m     \u001b[38;5;66;03m# remaining jobs.\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m-> 1085\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1088\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mapply_async(batch, callback\u001b[38;5;241m=\u001b[39mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m batch()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    684\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    685\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 686\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    688\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    689\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    690\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1291\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1288\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1289\u001b[0m     n_threads \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1291\u001b[0m fold_coefs_ \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose, prefer\u001b[38;5;241m=\u001b[39mprefer)(\n\u001b[0;32m   1292\u001b[0m     path_func(\n\u001b[0;32m   1293\u001b[0m         X,\n\u001b[0;32m   1294\u001b[0m         y,\n\u001b[0;32m   1295\u001b[0m         pos_class\u001b[38;5;241m=\u001b[39mclass_,\n\u001b[0;32m   1296\u001b[0m         Cs\u001b[38;5;241m=\u001b[39m[C_],\n\u001b[0;32m   1297\u001b[0m         l1_ratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ml1_ratio,\n\u001b[0;32m   1298\u001b[0m         fit_intercept\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_intercept,\n\u001b[0;32m   1299\u001b[0m         tol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtol,\n\u001b[0;32m   1300\u001b[0m         verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[0;32m   1301\u001b[0m         solver\u001b[38;5;241m=\u001b[39msolver,\n\u001b[0;32m   1302\u001b[0m         multi_class\u001b[38;5;241m=\u001b[39mmulti_class,\n\u001b[0;32m   1303\u001b[0m         max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_iter,\n\u001b[0;32m   1304\u001b[0m         class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight,\n\u001b[0;32m   1305\u001b[0m         check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1306\u001b[0m         random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state,\n\u001b[0;32m   1307\u001b[0m         coef\u001b[38;5;241m=\u001b[39mwarm_start_coef_,\n\u001b[0;32m   1308\u001b[0m         penalty\u001b[38;5;241m=\u001b[39mpenalty,\n\u001b[0;32m   1309\u001b[0m         max_squared_sum\u001b[38;5;241m=\u001b[39mmax_squared_sum,\n\u001b[0;32m   1310\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[0;32m   1311\u001b[0m         n_threads\u001b[38;5;241m=\u001b[39mn_threads,\n\u001b[0;32m   1312\u001b[0m     )\n\u001b[0;32m   1313\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m class_, warm_start_coef_ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(classes_, warm_start_coef)\n\u001b[0;32m   1314\u001b[0m )\n\u001b[0;32m   1316\u001b[0m fold_coefs_, _, n_iter_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mfold_coefs_)\n\u001b[0;32m   1317\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(n_iter_, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint32)[:, \u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1085\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1076\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1077\u001b[0m     \u001b[38;5;66;03m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[0;32m   1078\u001b[0m     \u001b[38;5;66;03m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1082\u001b[0m     \u001b[38;5;66;03m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[0;32m   1083\u001b[0m     \u001b[38;5;66;03m# remaining jobs.\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m-> 1085\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1088\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mapply_async(batch, callback\u001b[38;5;241m=\u001b[39mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m batch()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:450\u001b[0m, in \u001b[0;36m_logistic_regression_path\u001b[1;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio, n_threads)\u001b[0m\n\u001b[0;32m    446\u001b[0m l2_reg_strength \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m C\n\u001b[0;32m    447\u001b[0m iprint \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m101\u001b[39m][\n\u001b[0;32m    448\u001b[0m     np\u001b[38;5;241m.\u001b[39msearchsorted(np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m]), verbose)\n\u001b[0;32m    449\u001b[0m ]\n\u001b[1;32m--> 450\u001b[0m opt_res \u001b[38;5;241m=\u001b[39m optimize\u001b[38;5;241m.\u001b[39mminimize(\n\u001b[0;32m    451\u001b[0m     func,\n\u001b[0;32m    452\u001b[0m     w0,\n\u001b[0;32m    453\u001b[0m     method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL-BFGS-B\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    454\u001b[0m     jac\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    455\u001b[0m     args\u001b[38;5;241m=\u001b[39m(X, target, sample_weight, l2_reg_strength, n_threads),\n\u001b[0;32m    456\u001b[0m     options\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miprint\u001b[39m\u001b[38;5;124m\"\u001b[39m: iprint, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgtol\u001b[39m\u001b[38;5;124m\"\u001b[39m: tol, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaxiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_iter},\n\u001b[0;32m    457\u001b[0m )\n\u001b[0;32m    458\u001b[0m n_iter_i \u001b[38;5;241m=\u001b[39m _check_optimize_result(\n\u001b[0;32m    459\u001b[0m     solver,\n\u001b[0;32m    460\u001b[0m     opt_res,\n\u001b[0;32m    461\u001b[0m     max_iter,\n\u001b[0;32m    462\u001b[0m     extra_warning_msg\u001b[38;5;241m=\u001b[39m_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n\u001b[0;32m    463\u001b[0m )\n\u001b[0;32m    464\u001b[0m w0, loss \u001b[38;5;241m=\u001b[39m opt_res\u001b[38;5;241m.\u001b[39mx, opt_res\u001b[38;5;241m.\u001b[39mfun\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_minimize.py:696\u001b[0m, in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    693\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[0;32m    694\u001b[0m                              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[0;32m    695\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml-bfgs-b\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 696\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0;32m    697\u001b[0m                            callback\u001b[38;5;241m=\u001b[39mcallback, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtnc\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    699\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[0;32m    700\u001b[0m                         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py:353\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;66;03m# x, f, g, wa, iwa, task, csave, lsave, isave, dsave = \\\u001b[39;00m\n\u001b[0;32m    350\u001b[0m     _lbfgsb\u001b[38;5;241m.\u001b[39msetulb(m, x, low_bnd, upper_bnd, nbd, f, g, factr,\n\u001b[0;32m    351\u001b[0m                    pgtol, wa, iwa, task, iprint, csave, lsave,\n\u001b[0;32m    352\u001b[0m                    isave, dsave, maxls)\n\u001b[1;32m--> 353\u001b[0m     task_str \u001b[38;5;241m=\u001b[39m task\u001b[38;5;241m.\u001b[39mtobytes()\n\u001b[0;32m    354\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFG\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    355\u001b[0m         \u001b[38;5;66;03m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[0;32m    356\u001b[0m         \u001b[38;5;66;03m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[0;32m    357\u001b[0m         \u001b[38;5;66;03m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[0;32m    358\u001b[0m         \u001b[38;5;66;03m# Overwrite f and g:\u001b[39;00m\n\u001b[0;32m    359\u001b[0m         f, g \u001b[38;5;241m=\u001b[39m func_and_grad(x)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning for Logistic Regression\n",
    "param_grid_lr = {'C': [0.01, 0.1, 1, 10]}  # Regularization parameter\n",
    "\n",
    "lr_model = LogisticRegression(max_iter=20000, random_state=45)\n",
    "grid_search_lr = GridSearchCV(lr_model, param_grid_lr, cv=5)\n",
    "grid_search_lr.fit(X_train, y_train)\n",
    "\n",
    "best_lr_model = grid_search_lr.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d903b12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning for Random Forest\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [None, 5, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "grid_search_rf = GridSearchCV(rf_model, param_grid_rf, cv=5)\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "best_rf_model = grid_search_rf.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0037b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning for XGBoost\n",
    "param_grid_xgb = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0],\n",
    "}\n",
    "\n",
    "xgb_model = XGBClassifier(random_state=42)\n",
    "grid_search_xgb = GridSearchCV(xgb_model, param_grid_xgb, cv=5)\n",
    "grid_search_xgb.fit(X_train, y_train)\n",
    "\n",
    "best_xgb_model = grid_search_xgb.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbbb4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning for Decision Tree\n",
    "param_grid_dt = {\n",
    "    'max_depth': [None, 5, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "grid_search_dt = GridSearchCV(dt_model, param_grid_dt, cv=5)\n",
    "grid_search_dt.fit(X_train, y_train)\n",
    "\n",
    "best_dt_model = grid_search_dt.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c04a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation function\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy: {accuracy:.2f}\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # Feature importance for tree-based models\n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        importances = model.feature_importances_\n",
    "        features = X_test.columns\n",
    "        importance_df = pd.DataFrame({'Feature': features, 'Importance': importances})\n",
    "        importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.bar(importance_df['Feature'], importance_df['Importance'])\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.xlabel('Features')\n",
    "        plt.ylabel('Importance')\n",
    "        plt.title('Feature Importance')\n",
    "        plt.show()\n",
    "\n",
    "# Evaluate Logistic Regression\n",
    "print(\"Logistic Regression:\")\n",
    "evaluate_model(best_lr_model, X_test, y_test)\n",
    "\n",
    "# Evaluate Random Forest\n",
    "print(\"Random Forest:\")\n",
    "evaluate_model(best_rf_model, X_test, y_test)\n",
    "\n",
    "# Evaluate XGBoost\n",
    "print(\"XGBoost:\")\n",
    "evaluate_model(best_xgb_model, X_test, y_test)\n",
    "\n",
    "# Evaluate Decision Tree\n",
    "print(\"Decision Tree:\")\n",
    "evaluate_model(best_dt_model, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8576fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'song_popularity' is the target column, and other columns are features\n",
    "X = df_music.drop('class', axis=1)\n",
    "y = df_music['class']\n",
    "\n",
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803dc875",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Hyperparameter tuning for Logistic Regression\n",
    "param_grid_lr = {'C': [0.01, 0.1, 1, 10]}  # Regularization parameter\n",
    "\n",
    "lr_model = LogisticRegression(max_iter=2000, random_state=42)\n",
    "grid_search_lr = GridSearchCV(lr_model, param_grid_lr, cv=5)\n",
    "grid_search_lr.fit(X_train, y_train)\n",
    "\n",
    "best_lr_model = grid_search_lr.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac64bd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning for Random Forest\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [None, 5, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "grid_search_rf = GridSearchCV(rf_model, param_grid_rf, cv=5)\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "best_rf_model = grid_search_rf.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4c00e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning for XGBoost\n",
    "param_grid_xgb = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0],\n",
    "}\n",
    "\n",
    "xgb_model = XGBClassifier(random_state=42)\n",
    "grid_search_xgb = GridSearchCV(xgb_model, param_grid_xgb, cv=5)\n",
    "grid_search_xgb.fit(X_train, y_train)\n",
    "\n",
    "best_xgb_model = grid_search_xgb.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420ea458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning for Decision Tree\n",
    "param_grid_dt = {\n",
    "    'max_depth': [None, 5, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "grid_search_dt = GridSearchCV(dt_model, param_grid_dt, cv=5)\n",
    "grid_search_dt.fit(X_train, y_train)\n",
    "\n",
    "best_dt_model = grid_search_dt.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c22852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation function\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy: {accuracy:.2f}\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # Feature importance for tree-based models\n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        importances = model.feature_importances_\n",
    "        features = X_test.columns\n",
    "        importance_df = pd.DataFrame({'Feature': features, 'Importance': importances})\n",
    "        importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.bar(importance_df['Feature'], importance_df['Importance'])\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.xlabel('Features')\n",
    "        plt.ylabel('Importance')\n",
    "        plt.title('Feature Importance')\n",
    "        plt.show()\n",
    "\n",
    "# Evaluate Logistic Regression\n",
    "print(\"Logistic Regression:\")\n",
    "evaluate_model(best_lr_model, X_test, y_test)\n",
    "\n",
    "# Evaluate Random Forest\n",
    "print(\"Random Forest:\")\n",
    "evaluate_model(best_rf_model, X_test, y_test)\n",
    "\n",
    "# Evaluate XGBoost\n",
    "print(\"XGBoost:\")\n",
    "evaluate_model(best_xgb_model, X_test, y_test)\n",
    "\n",
    "# Evaluate Decision Tree\n",
    "print(\"Decision Tree:\")\n",
    "evaluate_model(best_dt_model, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cdbd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to map numeric encoding to genre labels\n",
    "encoding_to_genre = {\n",
    "    0: 'Acoustic/Folk',\n",
    "    1: 'Alt_Music',\n",
    "    2: 'Blues',\n",
    "    3: 'Bollywood',\n",
    "    4: 'Country',\n",
    "    5: 'HipHop',\n",
    "    6: 'Indie Alt',\n",
    "    7: 'Instrumental',\n",
    "    8: 'Metal',\n",
    "    9: 'Pop',\n",
    "    10: 'Rock'\n",
    "}\n",
    "\n",
    "# Replace numeric encoding with genre labels in the \"class\" column\n",
    "df_music['class'] = df_music['class'].astype(int)\n",
    "df_music['class'] = df_music['class'].map(encoding_to_genre)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
